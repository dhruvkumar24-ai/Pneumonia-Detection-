{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810},{"sourceId":847338,"sourceType":"datasetVersion","datasetId":255488}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style=\"font-family:verdana;\"> <center>üìö Pneumonia Detection using VGG16 Transfer Learningüìö</center> </h1>\n<p><center style=\"color:#159364; font-family:cursive;\">In this notebook, I have evaluated the performance of VGG16 Architecture by fine-tuning it on <code>Chest X-Ray Images(Pneumonia)</code> Dataset.</center></p>\n    <center>\n<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:verdana; line-height: 1.7em;\">\n    üìå &nbsp; In case this notebook is helpful to you in anyway, please do consider leaving feedback. Thanks! :)\n</div></center>\n\n***","metadata":{}},{"cell_type":"markdown","source":"\n# üéØ VGG-16 Model\n<div style=\"text-align:center;\">\n    <img  src=\"https://miro.medium.com/v2/resize:fit:850/1*_Lg1i7wv1pLpzp2F4MLrvw.png\" />\n</div>\nVGG-16 is a** Convolutional Neural Network** (CNN) model proposed by Karen Simonyan and Andrew Zisserman of the Visual Geometry Group Lab of Oxford University in 2014. It's considered one of the **best vision model architectures** to date. The model won 1st and 2nd place in the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2014.\n\n## üèóÔ∏è Architecture\n\nThe architecture of VGG-16 is uniform and consists of 16 convolutional layers. Here's a detailed breakdown:\n\n1. **üì• Input**: The input to the network is an image of dimensions (224, 224, 3).\n\n2. **üîÄ Convolutional Layers**: The first two layers have 64 channels of a 3x3 filter size and the same padding. Then, we have two layers of convolution layers of 128 filter size and filter size (3, 3). This is followed by 2 convolution layers of filter size (3, 3) and 256 filters. After that, there are 2 sets of 3 convolution layers. Each has 512 filters of (3, 3) size with the same padding.\n\n3. **üîΩ Max-Pooling Layers**: After each set of convolutional layers, there's a max-pooling layer of stride (2, 2).\n\n4. **üîÑ Activation Function**: The activation function used in the VGG-16 model is the Rectified Linear Unit (ReLU).\n\n5. **üîó Fully Connected Layers**: The last three layers of the VGG-16 model are fully connected layers.\n\n6. **üì§ Output**: The output of the model is a vector of 1000 values, representing the classification probability for the corresponding class.\n\n\n","metadata":{"papermill":{"duration":0.009285,"end_time":"2020-08-06T13:04:28.109023","exception":false,"start_time":"2020-08-06T13:04:28.099738","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"\n# üìö Import Libraries\n","metadata":{"papermill":{"duration":0.008955,"end_time":"2020-08-06T13:04:28.144508","exception":false,"start_time":"2020-08-06T13:04:28.135553","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%matplotlib inline\nimport copy\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd \nimport os\nimport seaborn as sns\nimport skimage\nfrom skimage import io, transform\nfrom sklearn.metrics import confusion_matrix\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import datasets, models, transforms","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":3.194649,"end_time":"2020-08-06T13:04:31.348337","exception":false,"start_time":"2020-08-06T13:04:28.153688","status":"completed"},"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2023-11-25T07:47:09.788269Z","iopub.execute_input":"2023-11-25T07:47:09.788986Z","iopub.status.idle":"2023-11-25T07:47:09.796361Z","shell.execute_reply.started":"2023-11-25T07:47:09.788952Z","shell.execute_reply":"2023-11-25T07:47:09.795452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üìÇ Load Dataset\n\nThe dataset respective to already classified category is divided into three sets:\n* test set\n* train set\n* validation set\n","metadata":{"papermill":{"duration":0.008031,"end_time":"2020-08-06T13:04:31.365788","exception":false,"start_time":"2020-08-06T13:04:31.357757","status":"completed"},"tags":[]}},{"cell_type":"code","source":"EPOCHS = 30\ndata_dir = \"../input/chest-xray-pneumonia/chest_xray/chest_xray\"\nTEST = 'test'\nTRAIN = 'train'\nVAL ='val'","metadata":{"_uuid":"a085308769971ac9a887dab713c4334df755463e","papermill":{"duration":0.015614,"end_time":"2020-08-06T13:04:31.389408","exception":false,"start_time":"2020-08-06T13:04:31.373794","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-25T07:47:10.174575Z","iopub.execute_input":"2023-11-25T07:47:10.174973Z","iopub.status.idle":"2023-11-25T07:47:10.179488Z","shell.execute_reply.started":"2023-11-25T07:47:10.174935Z","shell.execute_reply":"2023-11-25T07:47:10.178588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üöÄ Data Preprocessing and Augmentation\n\nDeep learning models typically require a substantial amount of data for training. Generally, the more data available, the better the model's performance. üìà\n\n**Image Augmentation** üé® is a technique used to generate new images for training our deep learning model. These new images are created using the existing training images, eliminating the need for manual collection. ","metadata":{"papermill":{"duration":0.007171,"end_time":"2020-08-06T13:04:31.404353","exception":false,"start_time":"2020-08-06T13:04:31.397182","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Define a function for data transformations\ndef data_transforms(phase):\n    # If the phase is TRAIN\n    if phase == TRAIN:\n        # Compose transformations: Resize, CenterCrop, Convert to Tensor, Normalize\n        transform = transforms.Compose([\n            transforms.Resize(256),  # Resize the image to 256x256 pixels\n            transforms.CenterCrop(224),  # Crop the center of the image to 224x224 pixels\n            transforms.ToTensor(),  # Convert the image to a PyTorch Tensor\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),  # Normalize the Tensor\n        ])\n        \n    # If the phase is VAL\n    if phase == VAL:\n        # Apply the same transformations as the TRAIN phase\n        transform = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        ])\n    \n    # If the phase is TEST\n    if phase == TEST:\n        # Apply the same transformations as the TRAIN phase\n        transform = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        ])        \n        \n    return transform  # Return the composed transformations\n\n# Check if CUDA is available and set the device accordingly\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)  # Print the device being used\n","metadata":{"_uuid":"3d225783b44656fe1a1a97f309cac6b40e578d7a","papermill":{"duration":0.384278,"end_time":"2020-08-06T13:04:31.796070","exception":false,"start_time":"2020-08-06T13:04:31.411792","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-25T07:47:10.506257Z","iopub.execute_input":"2023-11-25T07:47:10.506647Z","iopub.status.idle":"2023-11-25T07:47:10.515934Z","shell.execute_reply.started":"2023-11-25T07:47:10.506619Z","shell.execute_reply":"2023-11-25T07:47:10.514991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dictionary of datasets for each phase (TRAIN, VAL, TEST)\n# For each phase, load the images from the corresponding folder and apply the data transformations\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms(x)) \n                  for x in [TRAIN, VAL, TEST]}\n\n# Create a dictionary of dataloaders for each phase\n# For each phase, create a DataLoader that loads the data from the corresponding dataset\n# The batch size and shuffle parameters can be adjusted as needed\ndataloaders = {\n    TRAIN: torch.utils.data.DataLoader(image_datasets[TRAIN], batch_size = 4, shuffle=True), \n    VAL: torch.utils.data.DataLoader(image_datasets[VAL], batch_size = 1, shuffle=True), \n    TEST: torch.utils.data.DataLoader(image_datasets[TEST], batch_size = 1, shuffle=True)\n}\n","metadata":{"_uuid":"d26865aa0bf2ead92c0f10a0b90b786190d3653b","papermill":{"duration":0.907485,"end_time":"2020-08-06T13:04:32.712875","exception":false,"start_time":"2020-08-06T13:04:31.805390","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-25T07:47:10.699495Z","iopub.execute_input":"2023-11-25T07:47:10.699764Z","iopub.status.idle":"2023-11-25T07:47:11.617090Z","shell.execute_reply.started":"2023-11-25T07:47:10.699741Z","shell.execute_reply":"2023-11-25T07:47:11.616292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dataloaders[TRAIN])","metadata":{"_uuid":"334b931f0c48bc3d8b8df5d28d0c28f53fcb5391","papermill":{"duration":0.018017,"end_time":"2020-08-06T13:04:32.739653","exception":false,"start_time":"2020-08-06T13:04:32.721636","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-25T07:47:11.618677Z","iopub.execute_input":"2023-11-25T07:47:11.619393Z","iopub.status.idle":"2023-11-25T07:47:11.625093Z","shell.execute_reply.started":"2023-11-25T07:47:11.619356Z","shell.execute_reply":"2023-11-25T07:47:11.624255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the sizes of the datasets\ndataset_sizes = {\n    x: len(image_datasets[x]) \n    for x in [TRAIN, VAL]\n}\n\n# Get the classes from the training dataset\nclasses = image_datasets[TRAIN].classes\n\n# Get the class names from the training dataset\nclass_names = image_datasets[TRAIN].classes\n","metadata":{"_uuid":"2f8733bbbd9369fb75c871d66e552d8c3171476f","papermill":{"duration":0.015779,"end_time":"2020-08-06T13:04:32.763278","exception":false,"start_time":"2020-08-06T13:04:32.747499","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-25T07:47:11.909698Z","iopub.execute_input":"2023-11-25T07:47:11.910374Z","iopub.status.idle":"2023-11-25T07:47:11.915185Z","shell.execute_reply.started":"2023-11-25T07:47:11.910346Z","shell.execute_reply":"2023-11-25T07:47:11.914148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üñºÔ∏èVisualizing the Chest X-rays","metadata":{"papermill":{"duration":0.007794,"end_time":"2020-08-06T13:04:32.779159","exception":false,"start_time":"2020-08-06T13:04:32.771365","status":"completed"},"tags":[]}},{"cell_type":"code","source":"fig, axes = plt.subplots(6, 6, figsize=(12, 12))\nfig.subplots_adjust(hspace=0.3, wspace=0.3)\n\nfor i in range(6):\n    for j in range(6):\n        inputs, classes = next(iter(dataloaders[TRAIN]))\n        input_img = inputs[0]\n        class_label = classes[0]\n        inp = input_img.numpy().transpose((1, 2, 0))\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([0.229, 0.224, 0.225])\n        inp = std * inp + mean\n        inp = np.clip(inp, 0, 1)\n        axes[i, j].imshow(inp)\n        axes[i, j].set_title(class_names[class_label.item()])\n        axes[i, j].axis('off')\n\nplt.show()\n","metadata":{"_uuid":"3735bccee0248363ea457b98af01c9e745e6c172","papermill":{"duration":0.512844,"end_time":"2020-08-06T13:04:33.300393","exception":false,"start_time":"2020-08-06T13:04:32.787549","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-25T07:48:08.390335Z","iopub.execute_input":"2023-11-25T07:48:08.390728Z","iopub.status.idle":"2023-11-25T07:48:14.512966Z","shell.execute_reply.started":"2023-11-25T07:48:08.390697Z","shell.execute_reply":"2023-11-25T07:48:14.511966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs, classes = next(iter(dataloaders[TRAIN]))","metadata":{"_uuid":"45c60a298e32560aa4843652aa52348bbf360484","papermill":{"duration":0.106229,"end_time":"2020-08-06T13:04:33.415971","exception":false,"start_time":"2020-08-06T13:04:33.309742","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-25T07:48:14.514905Z","iopub.execute_input":"2023-11-25T07:48:14.515215Z","iopub.status.idle":"2023-11-25T07:48:14.587973Z","shell.execute_reply.started":"2023-11-25T07:48:14.515187Z","shell.execute_reply":"2023-11-25T07:48:14.587187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üöÄDefine Function for Training\n","metadata":{"papermill":{"duration":0.008434,"end_time":"2020-08-06T13:04:33.433413","exception":false,"start_time":"2020-08-06T13:04:33.424979","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs):\n    # Save the initial model weights\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    # Loop over the number of epochs\n    for epoch in range(num_epochs):\n        print(\"Epoch: {}/{}\".format(epoch+1, num_epochs))\n        print(\"=\"*10)\n        \n        # Each epoch has a training and validation phase\n        for phase in [TRAIN, VAL]:\n            if phase == TRAIN:\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data\n            for data in dataloaders[phase]:\n                inputs, labels = data\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # Zero the parameter gradients\n                optimizer.zero_grad()\n\n                # Forward pass\n                with torch.set_grad_enabled(phase==TRAIN):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # Backward pass and optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # Statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # Deep copy the model if we have a new best validation accuracy\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # Load best model weights and return the model\n    model.load_state_dict(best_model_wts)\n    return model\n","metadata":{"_uuid":"ef502f365bf5b30fddab9df0c24f9d8e2b994655","papermill":{"duration":0.027799,"end_time":"2020-08-06T13:04:33.469882","exception":false,"start_time":"2020-08-06T13:04:33.442083","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-25T07:48:14.589044Z","iopub.execute_input":"2023-11-25T07:48:14.589324Z","iopub.status.idle":"2023-11-25T07:48:14.601468Z","shell.execute_reply.started":"2023-11-25T07:48:14.589298Z","shell.execute_reply":"2023-11-25T07:48:14.600487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üîÑLoad the Pretrained Model","metadata":{"papermill":{"duration":0.008561,"end_time":"2020-08-06T13:04:33.487098","exception":false,"start_time":"2020-08-06T13:04:33.478537","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model_pre = models.vgg16()\nmodel_pre.load_state_dict(torch.load(\"../input/pytorch-pretrained-models/vgg16-397923af.pth\"))","metadata":{"_uuid":"bf8e30fc2773dfd38c66149bf6adc36e20d34a0c","papermill":{"duration":3.358694,"end_time":"2020-08-06T13:04:36.854450","exception":false,"start_time":"2020-08-06T13:04:33.495756","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-25T07:48:47.414768Z","iopub.execute_input":"2023-11-25T07:48:47.415144Z","iopub.status.idle":"2023-11-25T07:48:56.772333Z","shell.execute_reply.started":"2023-11-25T07:48:47.415114Z","shell.execute_reply":"2023-11-25T07:48:56.771302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for param in model_pre.features.parameters():\n    param.required_grad = False\n\nnum_features = model_pre.classifier[6].in_features\nfeatures = list(model_pre.classifier.children())[:-1] \nfeatures.extend([nn.Linear(num_features, len(class_names))])\nmodel_pre.classifier = nn.Sequential(*features) \nprint(model_pre)","metadata":{"_uuid":"b0259b0936dcd0ef57dc7fba27ed9f74c65a6b21","papermill":{"duration":0.02418,"end_time":"2020-08-06T13:04:36.889566","exception":false,"start_time":"2020-08-06T13:04:36.865386","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-25T07:49:00.013609Z","iopub.execute_input":"2023-11-25T07:49:00.014629Z","iopub.status.idle":"2023-11-25T07:49:00.021850Z","shell.execute_reply.started":"2023-11-25T07:49:00.014593Z","shell.execute_reply":"2023-11-25T07:49:00.020948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üîßDefine the Hyperparameters","metadata":{"papermill":{"duration":0.008471,"end_time":"2020-08-06T13:04:36.907205","exception":false,"start_time":"2020-08-06T13:04:36.898734","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model_pre = model_pre.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model_pre.parameters(), lr=0.001, momentum=0.9, weight_decay=0.01)\n# Decay LR by a factor of 0.1 every 10 epochs\nexp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)","metadata":{"_uuid":"133bcf43b18238f99bfc71e282c48ec1073c12b3","papermill":{"duration":4.81108,"end_time":"2020-08-06T13:04:41.726948","exception":false,"start_time":"2020-08-06T13:04:36.915868","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-25T07:49:11.006030Z","iopub.execute_input":"2023-11-25T07:49:11.007091Z","iopub.status.idle":"2023-11-25T07:49:11.159243Z","shell.execute_reply.started":"2023-11-25T07:49:11.007057Z","shell.execute_reply":"2023-11-25T07:49:11.158454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üöÇTrain Phase","metadata":{"papermill":{"duration":0.008876,"end_time":"2020-08-06T13:04:41.745328","exception":false,"start_time":"2020-08-06T13:04:41.736452","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model_pre = train_model(model_pre, criterion, optimizer, exp_lr_scheduler, num_epochs=EPOCHS)","metadata":{"_uuid":"08f9a3715e18dc954ea10c6d14202ad73a945b8e","papermill":{"duration":5176.57895,"end_time":"2020-08-06T14:30:58.333492","exception":false,"start_time":"2020-08-06T13:04:41.754542","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-25T07:48:36.907162Z","iopub.execute_input":"2023-11-25T07:48:36.908065Z","iopub.status.idle":"2023-11-25T07:48:36.940995Z","shell.execute_reply.started":"2023-11-25T07:48:36.908030Z","shell.execute_reply":"2023-11-25T07:48:36.939761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üìäEvaluate Model Performance\n","metadata":{"papermill":{"duration":0.012028,"end_time":"2020-08-06T14:30:58.406772","exception":false,"start_time":"2020-08-06T14:30:58.394744","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def test_model():\n    # Initialize counters\n    running_correct = 0.0\n    running_total = 0.0\n    true_labels = []\n    pred_labels = []\n    input_images = []\n\n    # No need to track gradients for testing\n    with torch.no_grad():\n        # Iterate over test data\n        for data in dataloaders[TEST]:\n            inputs, labels = data\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            # Store true labels\n            true_labels.append(labels.item())\n            \n            #Store model input images\n            input_images.append(inputs)\n            \n            # Forward pass\n            outputs = model_pre(inputs)\n            _, preds = torch.max(outputs.data, 1)\n\n            # Store predicted labels\n            pred_labels.append(preds.item())\n\n            # Update counters\n            running_total += labels.size(0)\n            running_correct += (preds == labels).sum().item()\n\n        # Calculate accuracy\n        acc = running_correct / running_total\n\n    return true_labels, pred_labels, input_images,  running_correct, running_total, acc\n","metadata":{"_uuid":"c0365bfeeca42d70cabbc1bfe8c7233b4e3874b3","papermill":{"duration":0.025384,"end_time":"2020-08-06T14:30:58.444277","exception":false,"start_time":"2020-08-06T14:30:58.418893","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-25T07:49:16.569229Z","iopub.execute_input":"2023-11-25T07:49:16.570152Z","iopub.status.idle":"2023-11-25T07:49:16.577549Z","shell.execute_reply.started":"2023-11-25T07:49:16.570119Z","shell.execute_reply":"2023-11-25T07:49:16.576561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üß™Testing Phase","metadata":{"papermill":{"duration":0.012244,"end_time":"2020-08-06T14:30:58.468582","exception":false,"start_time":"2020-08-06T14:30:58.456338","status":"completed"},"tags":[]}},{"cell_type":"code","source":"true_labels, pred_labels, input_images, running_correct, running_total, acc = test_model()","metadata":{"_uuid":"011a51335e5abb11acd3449d94f2faa165a20c2d","papermill":{"duration":16.893136,"end_time":"2020-08-06T14:31:15.374005","exception":false,"start_time":"2020-08-06T14:30:58.480869","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-25T07:49:17.655083Z","iopub.execute_input":"2023-11-25T07:49:17.655778Z","iopub.status.idle":"2023-11-25T07:49:39.931917Z","shell.execute_reply.started":"2023-11-25T07:49:17.655740Z","shell.execute_reply":"2023-11-25T07:49:39.931096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üìà Results","metadata":{"papermill":{"duration":0.012181,"end_time":"2020-08-06T14:31:15.400347","exception":false,"start_time":"2020-08-06T14:31:15.388166","status":"completed"},"tags":[]}},{"cell_type":"code","source":"fig, axes = plt.subplots(3,3, figsize=(7, 7))\nfig.subplots_adjust(hspace=0.7, wspace=0.7)\nx=0\nfor i in range(3):\n    for j in range(3):\n        # Get the image and labels\n        inp = input_images[x].squeeze()\n      \n        true_label = true_labels[x]\n        pred_label = pred_labels[x]\n\n        # Normalize the image for display\n        inp = inp.cpu().numpy().transpose((1, 2, 0))\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([0.229, 0.224, 0.225])\n        inp = std * inp + mean\n        inp = np.clip(inp, 0, 1)\n\n        # Display the image\n        axes[i, j].imshow(inp)\n\n        # Set the title with the predicted and actual labels\n        title = \"Predicted: {}\\nActual: {}\".format(class_names[pred_label], class_names[true_label])\n        color = 'green' if pred_label == true_label else 'red'\n        axes[i, j].set_title(title, color=color)\n\n        # Hide the axes\n        axes[i, j].axis('off')\n\n        # Move to the next image\n        x += 1\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-25T07:53:17.217454Z","iopub.execute_input":"2023-11-25T07:53:17.218143Z","iopub.status.idle":"2023-11-25T07:53:17.880051Z","shell.execute_reply.started":"2023-11-25T07:53:17.218110Z","shell.execute_reply":"2023-11-25T07:53:17.879136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Total Correct: {} \\nTotal Test Images: {}\".format(running_correct, running_total))\nprint(\"Test Accuracy: \", acc)\n\n\n","metadata":{"papermill":{"duration":0.022939,"end_time":"2020-08-06T14:31:15.435649","exception":false,"start_time":"2020-08-06T14:31:15.412710","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}